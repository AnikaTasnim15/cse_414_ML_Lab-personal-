


#1) Simulate a Dataset for Simple Linear Regression

import numpy as np
import matplotlib.pyplot as plt


np.random.seed(42)

# Generate data: x1 is the feature (e.g., house size), y is the target (e.g., price)
m = 100  # number of data points
x1 = 2 * np.random.rand(m, 1)  # feature: house size (e.g., between 0 and 2)
theta_0 = 3  # intercept (bias)
theta_1 = 5  # slope (weight)
y = theta_0 + theta_1 * x1 + np.random.randn(m, 1)  # add noise

# Visualize the data
plt.scatter(x1, y, color='blue', label='Data points')
plt.xlabel('House Size (x1)')
plt.ylabel('Price (y)')
plt.title('House Size vs Price')
plt.show()


# 2) Implementing Linear Regression with Normal Equation

# Step 1: Calculate the means of x1 and y
x1_mean = np.mean(x1)
y_mean = np.mean(y)

# Step 2: Calculate the slope (theta_1)
numerator = np.sum((x1 - x1_mean) * (y - y_mean))
denominator = np.sum((x1 - x1_mean) ** 2)
theta_1_manual = numerator / denominator

# Step 3: Calculate the intercept (theta_0)
theta_0_manual = y_mean - (theta_1_manual * x1_mean)

# Print the results
print(f"Calculated theta_0 (Intercept): {theta_0_manual}")
print(f"Calculated theta_1 (Slope): {theta_1_manual}")





# Step 4: Predicting for a new test case (e.g., x1 = 1.5)
x1_test = 1.5  # New feature value (house size)
y_pred = theta_0_manual + theta_1_manual * x1_test

print(f"Predicted value of y for x1 = {x1_test}: {y_pred}")





import numpy as np

# Generate multiple features (e.g., x1, x2, x3)
np.random.seed(42)
x1 = 2 * np.random.rand(100, 1)  # First feature (e.g., house size)
x2 = 3 * np.random.rand(100, 1)  # Second feature (e.g., number of rooms)
x3 = 2 * np.random.rand(100, 1)  # Third feature (e.g., age of the house)

# Combine them into the feature matrix X (including intercept term)
X_multi = np.c_[np.ones((100, 1)), x1, x2, x3]  # Add a column of 1s for the intercept

# Set new target y based on a linear combination of features and some noise
theta_multi_true = np.array([3, 5, 1, -2])  # True theta values
y_multi = X_multi.dot(theta_multi_true) + np.random.randn(100, 1)  # Target variable with noise

# Step 1: Calculate means of features and target
X_mean = np.mean(X_multi, axis=0)
y_mean = np.mean(y_multi)

# Step 2: Calculate the covariance terms (for theta_1, theta_2, theta_3)
cov_x1_y = np.sum((x1 - X_mean[1]) * (y_multi - y_mean))
cov_x2_y = np.sum((x2 - X_mean[2]) * (y_multi - y_mean))
cov_x3_y = np.sum((x3 - X_mean[3]) * (y_multi - y_mean))

cov_x1_x1 = np.sum((x1 - X_mean[1]) ** 2)
cov_x2_x2 = np.sum((x2 - X_mean[2]) ** 2)
cov_x3_x3 = np.sum((x3 - X_mean[3]) ** 2)

# Step 3: Calculate the slopes (theta_1, theta_2, theta_3) using covariance
theta_1_manual = cov_x1_y / cov_x1_x1
theta_2_manual = cov_x2_y / cov_x2_x2
theta_3_manual = cov_x3_y / cov_x3_x3

# Step 4: Calculate the intercept (theta_0) manually
theta_0_manual = y_mean - (theta_1_manual * X_mean[1] + theta_2_manual * X_mean[2] + theta_3_manual * X_mean[3])

# Print the manually calculated theta values
print(f"Manually calculated intercept (theta_0): {theta_0_manual}")
print(f"Manually calculated slope (theta_1): {theta_1_manual}")
print(f"Manually calculated slope (theta_2): {theta_2_manual}")
print(f"Manually calculated slope (theta_3): {theta_3_manual}")


# Step 5: Predicting for a new test case with multiple features
X_test_multi = np.array([1, 1.5, 2.0, 0.8])  # [intercept, x1, x2, x3]
y_pred_manual = X_test_multi.dot([theta_0_manual, theta_1_manual, theta_2_manual, theta_3_manual])

print(f"Predicted value of y for the new test case with multiple features: {y_pred_manual}")
